{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_ai_essays():\n",
        "    import openai\n",
        "\n",
        "    openai.organization = os.getenv(\"OPENAI_ORG\")\n",
        "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    prompt_dir = Path(\"./data/prompts/\").absolute()\n",
        "    essay_dir = Path(\"./data/essays/\").absolute()\n",
        "\n",
        "    generated_essays = {}\n",
        "\n",
        "    for prompt_file_path in prompt_dir.iterdir():\n",
        "        prompt_number = int(\n",
        "            prompt_file_path.name.removeprefix(\"prompt_\").removesuffix(\".txt\")\n",
        "        )\n",
        "\n",
        "        if (essay_dir / f\"gpt_{prompt_number}.txt\").exists():\n",
        "            essay_file_path = essay_dir / f\"gpt_{prompt_number}.txt\"\n",
        "\n",
        "            with essay_file_path.open(\"r\") as essay_file:\n",
        "                essay = essay_file.read().replace(\"\\n\", \"\")\n",
        "                generated_essays[prompt_number] = essay\n",
        "\n",
        "        else:\n",
        "            with prompt_file_path.open(\"r\") as prompt_file:\n",
        "                prompt = prompt_file.read().replace(\"\\n\", \"\")\n",
        "\n",
        "                generated_essays[prompt_number] = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-3.5-turbo\", \n",
        "                    # max_tokens=2048, # defaults to infinity\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\":\"You are an essay writer.\"},\n",
        "                        {\"role\": \"user\", \"content\": prompt},\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "    return generated_essays\n",
        "\n",
        "\n",
        "generated_essays = generate_ai_essays()\n",
        "\n",
        "essay_dir = Path(\"./data/essays/\").absolute()\n",
        "\n",
        "for number, message in generated_essays.items():\n",
        "    essay_file = essay_dir / f\"gpt_{number}.txt\"\n",
        "    essay_file.write_text(message.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6130fcb82071ae0e945256866b952593 in your message.)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m         essay_file \u001b[39m=\u001b[39m essay_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt_\u001b[39m\u001b[39m{\u001b[39;00mnumber\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         essay_file\u001b[39m.\u001b[39mwrite_text(message\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent)\n\u001b[0;32m---> 52\u001b[0m \u001b[39mawait\u001b[39;00m generate_essays_async()\n",
            "Cell \u001b[0;32mIn[59], line 40\u001b[0m, in \u001b[0;36mgenerate_essays_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         prompt \u001b[39m=\u001b[39m prompt_file\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m         prompts[prompt_number] \u001b[39m=\u001b[39m prompt\n\u001b[0;32m---> 40\u001b[0m generated_essays \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\n\u001b[1;32m     41\u001b[0m     \u001b[39m*\u001b[39m[\n\u001b[1;32m     42\u001b[0m         asyncio\u001b[39m.\u001b[39mensure_future(create_chat_completion(prompt))\n\u001b[1;32m     43\u001b[0m         \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m     44\u001b[0m     ]\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m number, message \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(generated_essays):\n\u001b[1;32m     48\u001b[0m     essay_file \u001b[39m=\u001b[39m essay_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt_\u001b[39m\u001b[39m{\u001b[39;00mnumber\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m\n",
            "Cell \u001b[0;32mIn[59], line 8\u001b[0m, in \u001b[0;36mcreate_chat_completion\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_chat_completion\u001b[39m(prompt: \u001b[39mstr\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m sem:\n\u001b[0;32m----> 8\u001b[0m         completion \u001b[39m=\u001b[39m  \u001b[39mawait\u001b[39;00m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39macreate(\n\u001b[1;32m      9\u001b[0m             model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m             \u001b[39m# max_tokens=2048, # defaults to infinity\u001b[39;00m\n\u001b[1;32m     11\u001b[0m             messages\u001b[39m=\u001b[39m[\n\u001b[1;32m     12\u001b[0m                 {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are an essay writer.\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     13\u001b[0m                 {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt},\n\u001b[1;32m     14\u001b[0m             ],\n\u001b[1;32m     15\u001b[0m         )\n\u001b[1;32m     17\u001b[0m         \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m~/projects/python/ap stat final project/.venv/lib64/python3.11/site-packages/openai/api_resources/chat_completion.py:45\u001b[0m, in \u001b[0;36mChatCompletion.acreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39macreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     47\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m~/projects/python/ap stat final project/.venv/lib64/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:217\u001b[0m, in \u001b[0;36mEngineAPIResource.acreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39macreate\u001b[39m(\n\u001b[1;32m    194\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    202\u001b[0m ):\n\u001b[1;32m    203\u001b[0m     (\n\u001b[1;32m    204\u001b[0m         deployment_id,\n\u001b[1;32m    205\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    216\u001b[0m     )\n\u001b[0;32m--> 217\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m requestor\u001b[39m.\u001b[39marequest(\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         url,\n\u001b[1;32m    220\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    221\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    222\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    228\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    229\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/projects/python/ap stat final project/.venv/lib64/python3.11/site-packages/openai/api_requestor.py:314\u001b[0m, in \u001b[0;36mAPIRequestor.arequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marequest_raw(\n\u001b[1;32m    305\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    306\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    313\u001b[0m     )\n\u001b[0;32m--> 314\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_async_response(result, stream)\n\u001b[1;32m    315\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mawait\u001b[39;00m ctx\u001b[39m.\u001b[39m\u001b[39m__aexit__\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[0;32m~/projects/python/ap stat final project/.venv/lib64/python3.11/site-packages/openai/api_requestor.py:650\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_async_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mexcept\u001b[39;00m aiohttp\u001b[39m.\u001b[39mClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    648\u001b[0m     util\u001b[39m.\u001b[39mlog_warn(e, body\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39mcontent)\n\u001b[1;32m    649\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    651\u001b[0m         (\u001b[39mawait\u001b[39;49;00m result\u001b[39m.\u001b[39;49mread())\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    652\u001b[0m         result\u001b[39m.\u001b[39;49mstatus,\n\u001b[1;32m    653\u001b[0m         result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    654\u001b[0m         stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    655\u001b[0m     ),\n\u001b[1;32m    656\u001b[0m     \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    657\u001b[0m )\n",
            "File \u001b[0;32m~/projects/python/ap stat final project/.venv/lib64/python3.11/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6130fcb82071ae0e945256866b952593 in your message.)"
          ]
        }
      ],
      "source": [
        "import openai, asyncio\n",
        "\n",
        "sem = asyncio.Semaphore(30)\n",
        "\n",
        "\n",
        "async def create_chat_completion(prompt: str):\n",
        "    async with sem:\n",
        "        completion =  await openai.ChatCompletion.acreate(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            # max_tokens=2048, # defaults to infinity\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an essay writer.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        await asyncio.sleep(1)\n",
        "        return completion\n",
        "\n",
        "\n",
        "async def generate_essays_async():\n",
        "    openai.organization = os.getenv(\"OPENAI_ORG\")\n",
        "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    prompt_dir = Path(\"./data/prompts/\").absolute()\n",
        "    essay_dir = Path(\"./data/essays/\").absolute()\n",
        "\n",
        "    prompts = {}\n",
        "\n",
        "    for prompt_file_path in prompt_dir.iterdir():\n",
        "        prompt_number = int(\n",
        "            prompt_file_path.name.removeprefix(\"prompt_\").removesuffix(\".txt\")\n",
        "        )\n",
        "\n",
        "        with prompt_file_path.open(\"r\") as prompt_file:\n",
        "            prompt = prompt_file.read().replace(\"\\n\", \"\")\n",
        "\n",
        "            prompts[prompt_number] = prompt\n",
        "\n",
        "    generated_essays = await asyncio.gather(\n",
        "        *[\n",
        "            asyncio.ensure_future(create_chat_completion(prompt))\n",
        "            for prompt in prompts.values()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    for number, message in enumerate(generated_essays):\n",
        "        essay_file = essay_dir / f\"gpt_{number}.txt\"\n",
        "        essay_file.write_text(message.choices[0].message.content)\n",
        "\n",
        "\n",
        "await generate_essays_async()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_name</th>\n",
              "      <th>essay</th>\n",
              "      <th>words</th>\n",
              "      <th>chars</th>\n",
              "      <th>is_gpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>human_1.txt</td>\n",
              "      <td>The protagonist Yossarian in Joseph Heller's C...</td>\n",
              "      <td>916</td>\n",
              "      <td>4451</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>human_2.txt</td>\n",
              "      <td>Steven Pinker’s “A History of Violence: Edge M...</td>\n",
              "      <td>577</td>\n",
              "      <td>3049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>human_3.txt</td>\n",
              "      <td>In the play “Death of a Salesman”, the four ma...</td>\n",
              "      <td>581</td>\n",
              "      <td>2765</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>human_4.txt</td>\n",
              "      <td>In the novel A Portrait of the Artist as a You...</td>\n",
              "      <td>420</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>human_5.txt</td>\n",
              "      <td>Fashion is a puzzling topic. Fashion appeals t...</td>\n",
              "      <td>377</td>\n",
              "      <td>1959</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>gpt_54.txt</td>\n",
              "      <td>In Jon Krakauer’s novel, Into The Wild, Christ...</td>\n",
              "      <td>416</td>\n",
              "      <td>2300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>gpt_55.txt</td>\n",
              "      <td>Umberto Eco's essay \"Ur-Fascism\" defines fasci...</td>\n",
              "      <td>125</td>\n",
              "      <td>651</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>gpt_56.txt</td>\n",
              "      <td>In Ray Bradbury's \"The Pedestrian,\" the light ...</td>\n",
              "      <td>115</td>\n",
              "      <td>589</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>gpt_57.txt</td>\n",
              "      <td>In the dimly lit streets of Victorian London, ...</td>\n",
              "      <td>154</td>\n",
              "      <td>608</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>gpt_58.txt</td>\n",
              "      <td>A fish would be more efficient at passing on e...</td>\n",
              "      <td>126</td>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_name                                              essay  words  \\\n",
              "0    human_1.txt  The protagonist Yossarian in Joseph Heller's C...    916   \n",
              "1    human_2.txt  Steven Pinker’s “A History of Violence: Edge M...    577   \n",
              "2    human_3.txt  In the play “Death of a Salesman”, the four ma...    581   \n",
              "3    human_4.txt  In the novel A Portrait of the Artist as a You...    420   \n",
              "4    human_5.txt  Fashion is a puzzling topic. Fashion appeals t...    377   \n",
              "..           ...                                                ...    ...   \n",
              "111   gpt_54.txt  In Jon Krakauer’s novel, Into The Wild, Christ...    416   \n",
              "112   gpt_55.txt  Umberto Eco's essay \"Ur-Fascism\" defines fasci...    125   \n",
              "113   gpt_56.txt  In Ray Bradbury's \"The Pedestrian,\" the light ...    115   \n",
              "114   gpt_57.txt  In the dimly lit streets of Victorian London, ...    154   \n",
              "115   gpt_58.txt  A fish would be more efficient at passing on e...    126   \n",
              "\n",
              "     chars  is_gpt  \n",
              "0     4451       0  \n",
              "1     3049       0  \n",
              "2     2765       0  \n",
              "3     2099       0  \n",
              "4     1959       0  \n",
              "..     ...     ...  \n",
              "111   2300       1  \n",
              "112    651       1  \n",
              "113    589       1  \n",
              "114    608       1  \n",
              "115    615       1  \n",
              "\n",
              "[112 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"./data/dataset.csv\")\n",
        "\n",
        "\n",
        "def preproccess(dataset: pd.DataFrame):\n",
        "    wrong_indexes_train = []\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        if row[\"words\"] < 100:\n",
        "            wrong_indexes_train.append(index)\n",
        "\n",
        "    if wrong_indexes_train != []:\n",
        "        dataset.loc[wrong_indexes_train].to_csv('./data/dropped_rows.csv')\n",
        "        dataset.drop(index=wrong_indexes_train, inplace=True)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def dataset_to_csv():\n",
        "    dataset = pd.DataFrame()\n",
        "\n",
        "    essay_dir = Path(\"./data/essays/\").absolute()\n",
        "    essay_name = []\n",
        "    essays = []\n",
        "    words = []\n",
        "    chars = []\n",
        "    is_gpt = []\n",
        "\n",
        "    for essay_path in essay_dir.iterdir():\n",
        "        essay_name.append(essay_path.name)\n",
        "\n",
        "        if essay_path.name.split(\"_\")[0] == \"gpt\":\n",
        "            is_gpt.append(1)\n",
        "        else:\n",
        "            is_gpt.append(0)\n",
        "\n",
        "        with essay_path.open(\"r\") as essay:\n",
        "            essay = essay.read().replace(\"\\n\", \"\")\n",
        "            essays.append(essay)\n",
        "            words.append(len(essay.split(\" \")))\n",
        "            chars.append(len(list(essay.replace(\" \", \"\"))))\n",
        "\n",
        "    dataset = pd.DataFrame(\n",
        "        {\n",
        "            \"essay_name\": essay_name,\n",
        "            \"essay\": essays,\n",
        "            \"words\": words,\n",
        "            \"chars\": chars,\n",
        "            \"is_gpt\": is_gpt,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    dataset = preproccess(dataset)\n",
        "\n",
        "    dataset.to_csv(Path(\"./data/dataset.csv\"), index=False)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "dataset_to_csv()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
