{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os, requests\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "dataset = pd.read_csv(Path(\"./data/dataset.csv\"))\n",
        "\n",
        "for index, row in dataset.iterrows():\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def originality_ai_output(dataset: pd.DataFrame):\n",
        "    # label records with orginality.ai\n",
        "    url = \"https://api.originality.ai/api/v1/scan/ai\"\n",
        "    originality_api_key = os.getenv(\"ORIGINALITY_API_KEY\")\n",
        "\n",
        "    originality_score_original, originality_score_ai, originality_score_overall = [\n",
        "        {},\n",
        "        {},\n",
        "        {},\n",
        "    ]\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        payload = {\"content\": row[\"essay\"], \"aiModelVersion\": \"1\"}\n",
        "        headers = {\"X-OAI-API-KEY\": originality_api_key, \"Accept\": \"application/json\"}\n",
        "\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            score = response.json()[\"score\"]\n",
        "            originality_score_original[index] = score[\"original\"]\n",
        "            originality_score_ai[index] = score[\"ai\"]\n",
        "\n",
        "            if score[\"original\"] < score[\"ai\"]:\n",
        "                originality_score_overall[index] = 1\n",
        "            else:\n",
        "                originality_score_overall[index] = 0\n",
        "        else:\n",
        "            print(response.text)\n",
        "            break\n",
        "\n",
        "    dataset[\"originality_score_ai\"] = originality_score_ai\n",
        "    dataset[\"originality_score_original\"] = originality_score_original\n",
        "    dataset[\"originality_score_overall\"] = originality_score_overall\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "dataset = originality_ai_output(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gptzero_output(dataset: pd.DataFrame):\n",
        "    # label records with gptzero\n",
        "    url = \"https://api.gptzero.me/v2/predict/text\"\n",
        "    gptzero_api_key = os.getenv(\"GPTZERO_API_KEY\")\n",
        "\n",
        "    (\n",
        "        gptzero_score_average,\n",
        "        gptzero_score_ai,\n",
        "        gptzero_burstiness,\n",
        "        gptzero_score_overall,\n",
        "    ) = [{}, {}, {}, {}]\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        payload = {\"document\": row[\"essay\"]}\n",
        "        headers = {\n",
        "            \"Accept\": \"application/json\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"x-api-key\": gptzero_api_key,\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            average_generated_prob = response.json()[\"documents\"][0][\n",
        "                \"average_generated_prob\"\n",
        "            ]\n",
        "            completely_generated_prob = response.json()[\"documents\"][0][\n",
        "                \"completely_generated_prob\"\n",
        "            ]\n",
        "            overall_burstiness = response.json()[\"documents\"][0][\"overall_burstiness\"]\n",
        "\n",
        "            gptzero_score_average[index] = average_generated_prob\n",
        "            gptzero_score_ai[index] = completely_generated_prob\n",
        "            gptzero_burstiness[index] = overall_burstiness\n",
        "\n",
        "            if completely_generated_prob > 0.5:\n",
        "                gptzero_score_overall[index] = 1\n",
        "            else:\n",
        "                gptzero_score_overall[index] = 0\n",
        "        else:\n",
        "            print(response.text)\n",
        "            break\n",
        "\n",
        "    dataset[\"gptzero_score_ai\"] = gptzero_score_ai\n",
        "    dataset[\"gptzero_score_average\"] = gptzero_score_average\n",
        "    dataset[\"gptzero_score_overall\"] = gptzero_score_overall\n",
        "    dataset[\"gptzero_burstiness\"] = gptzero_burstiness\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "dataset = gptzero_output(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del dataset[\"essay\"]\n",
        "del dataset[\"chars\"]\n",
        "del dataset[\"words\"]\n",
        "dataset.to_csv(Path('./results/results.csv'), index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
